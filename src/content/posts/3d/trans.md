---
title: 'GeoTexBuild: ... from Map Footprints翻译'
published: 2025-04-22
description: "关于论文GeoTexBuild: 3D Building Model Generation from Map Footprints.的全文翻译"
tags: [3d,python,paper]
category: paper
draft: false
---
论文《GeoTexBuild: 基于地图足迹的3D建筑模型生成》的全文翻译：


### arXiv:2504.08419v1 [cs.CV] 2025年4月11日
### GeoTexBuild: 基于地图足迹的3D建筑模型生成
Ruizhe Wang, Junyan Yang, Qiao Wang  
东南大学  
**摘要**  
我们介绍了GeoTexBuild，这是一个从地图足迹生成3D建筑模型的模块化生成框架。该框架采用三阶段流程，包括高度图生成、几何重建和外观风格化，最终生成具有复杂几何和外观属性的建筑模型。通过集成定制的ControlNet和Text2Mesh模型，我们探索了在生成过程中控制几何和视觉属性的有效方法，从而解决了现有3D生成技术中单一立面照片背后的结构变化问题。每个阶段的实验结果验证了GeoTexBuild从场地规划或地图设计中提取的足迹生成详细准确建筑模型的能力。我们的框架显著减少了建筑建模的人工劳动，并可为设计师提供灵感。

**关键词**：3D建筑生成，模块化框架，几何控制，外观风格化


### 1 引言
建筑模型在城市规划[68]、旅游、视频游戏设计、电影制作[61]和虚拟现实[79]应用中起着关键作用。然而，建筑结构的内在复杂性意味着针对特定设计要求的自动化和可控建模仍是一个需要进一步探索的领域[81]。一方面，使用CAD软件[5]手动构建许多建筑模型既耗时又费力。另一方面，尽管近年来3D重建技术[26,40,20,71,39,32,50,2,48]取得了显著进展，但这些方法在多个方面受到限制：它们无法生成现实中不存在的新建筑，通常需要大量且昂贵的数据收集[73,92,85]，因此不太适合在早期规划和设计阶段应用。

由于建筑几何结构的固有复杂性[44]，准确的3D建筑建模需要的不仅仅是单张立面图像。这种复杂性不仅包括立面，还包括结构设计、高度和组件比例，而街景图像或相同的立面设计无法充分捕捉这些信息[57]。因此，这一限制需要探索能够更有效地封装和调节建筑物整体几何特征的特征。

不幸的是，现有的3D生成技术[60,63,41,89,4,76,9,67,72,82,29,96,53]依赖于单张照片或文本提示，往往缺乏详细结构所需的几何精度。这些方法严重依赖预训练模型，未能考虑几何中关键的特定设计参数，使其不足以满足细致的建筑应用。

地图上的一个自然特征可以作为有效的几何控制参数：建筑足迹（图1）。在城市规划和游戏设计中，专业系统和人员通常事先制定场地规划[43]或地图设计[49]，这些规划决定了建筑位置、建筑面积和足迹形状等关键参数。我们旨在开发一种生成方法，生成符合这些设计师指定控制条件的纹理化建筑模型，将预定义属性与简单的手绘草图和文本提示有效结合，从而显著减少人工劳动并为设计师提供灵感。

为了实现这一目标，我们提出了GeoTexBuild（图2），这是一个三阶段策略的生成框架：高度图生成、几何重建和外观风格化。第一步，我们结合ControlNet[94]来融合建筑足迹和手绘高度图的信息，从而实现屋顶结构的可控生成。随后，从生成的屋顶结构和特定输入参数中重建建筑的整体几何形状，得到一个无纹理的模型。最后，我们利用Text2Mesh[46]的风格化功能，为模型赋予详细的几何形状和颜色，形成一个完整的纹理化建筑模型。我们在表1中比较了所提出方法与其他方法的目标和特点。

[//]: # (![图1：&#40;a&#41;OpenStreetMap上的真实世界地图中的建筑足迹，&#40;b&#41;游戏设计中的虚构地图。其中一个足迹用红色突出显示以展示其轮廓。]&#40;图1&#41;)

**表1：建筑建模方法的目标和功能比较**  
（表格内容略，原文见）

在实验中，我们训练了几个定制的ControlNet，以研究不同图像条件对屋顶结构生成控制的影响。此外，我们修改了Text2Mesh模块，以提高建筑生成的风格化质量。从不同角度进行的大量实验证实了我们框架在建筑模型生成中的有效性。

GeoTexBuild有潜力弥合创意愿景与技术执行之间的差距，实现高度定制化建筑设计的轻松实现。此外，这种方法还可以启发相邻领域的进步，例如内外生成设计的结合或用于设计和规划的自动城市美学分析。我们的模块化框架中的模块可以替换为较新的预训练模型，使我们能够利用快速发展的视觉和语言研究中的最新和未来进展，因此它可以成为未来创新的基础。

总之，我们的贡献如下：
- 我们提出了一个模块化框架GeoTexBuild，用于从足迹生成具有详细可控几何和外观属性的建筑模型，从而显著减少所需的人工劳动并为设计师提供灵感。
- 我们通过将生成过程分为三个阶段并利用正交视图中的2D空间条件，研究了如何控制建筑生成的几何属性。
- 我们训练了一个定制的ControlNet和一个Text2Mesh模块，并将它们集成到我们的建筑生成框架中，使用了Building3D数据集的变体和精心挑选的建筑图像。
- 每个阶段的实验证明了我们框架和微调模型的有效性。


### 2 相关工作
#### 2.1 基于重建的建筑建模
除了手动建模外，最早的建筑自动建模方法包括基于从现实或专业知识获取的数据重建结构的各种方法[42,37,1]。这些方法通常涉及从卫星图像[33,59]、航空摄影[8,13]、多张照片[15,14,16,57,65,48,32,39]、点云[52,56,84,10,23,83]或激光雷达数据[30,17,27]重建建筑物。基于专业经验的自动建模通常采用过程化建模技术[54,58]和从收集的数据生成建筑语法的方法[47,70]。

近年来，传统方法已与深度学习或优化技术相结合[8,13,57,65,52,10,83]， either更新这些方法中的计算逻辑或改变数据量要求。此外，除了建筑物之外，还出现了用于一般3D重建的新方法[7,18,19]。这些创新方法[26,20,39,32,50,2,48]重新定义了3D数据表示或引入了新的重建算法，提高了重建的效率和保真度。它们能够同时将几何和颜色恢复到照片级真实感水平。

这些重建方法增进了我们对建模和生成过程的理解，并为生成建立了方法框架和数据基础。

#### 2.2 3D生成
3D生成技术主要有两类：一类强调单个对象的生成，另一类侧重于场景（背景）生成[36,28,55,93,90]。也存在用于建模3D城市环境的生成方法[98,35,87,66]，但它们的重点通常不包括单个建筑的详细几何形状。因此，本节主要围绕单对象生成技术展开。

起源于重建任务的3D生成技术最近发展迅速。这些技术不是旨在生成特定对象，而是可以生成由其数据集决定的各种对象。一些3D生成模型只能生成形状[86]，而另一些则可以同时生成形状和外观[38]。

根据输入，3D生成模型主要有两大流派：文本到3D[34]和图像到3D[38]。根据它们的3D表示，这些模型可以进一步分为显式表示（如基于点云的[53,81,97]、基于网格的[69,95]、基于体素的[64]和基于3DGS的[89,76]）、隐式表示（如基于NeRF的[60,63]和基于神经隐式表面的[29]）和混合表示（如基于潜在的[96,45]、基于三平面的[25,74]和基于多层表示的[90]）。

关于生成策略，模型可以采用基于多视图优化的[72,67,76,89,63,60]、前馈的[41,4,82,25,74,95,88]或过程化的方法[22]。根据训练数据，它们可以分为在3D数据上训练的模型[4,82,25,74,95,88]、在多视图2D图像上训练的模型[72,76,89,63,60]和在单视图图像上训练的模型[81]。这些模型在复杂性、训练成本、所需数据量、生成质量、可控性和应用便利性方面存在差异。

#### 2.3 3D模型编辑和风格化
在几何生成阶段之后，需要向3D模型中加入外观。在其他情况下，需要修改现有几何模型的外观。这些修改是通过编辑和外观风格化技术实现的。某些方法仅专注于改变3D模型的视觉属性，例如生成纹理和调整颜色属性[12,91,3]，而另一些方法则强调局部几何特征的细化[80]。考虑到几何和外观的相互依赖关系，一些方法旨在同时修改局部几何和颜色属性[46,21,77]。


### 3 方法
#### 3.1 公式化
我们的目标是在足迹、屋顶结构提示和建筑风格描述的条件下生成具有详细外观的3D建筑模型。考虑到可行性、控制精度和便利性之间的权衡，我们将足迹和屋顶结构作为图像输入，即遮罩和高度草图，将风格描述作为文本输入。为此，我们提出了GeoTexBuild，这是一个模块化框架，允许轻松准确的控制，并生成各种建筑样式的风格化3D模型。

为了更好地理解我们的框架，我们首先在3.2节介绍两个重要的外部模块，然后在3.3节概述我们的流程，并在3.4节详细介绍每个组件。

#### 3.2 预备知识
##### 3.2.1 ControlNet
ControlNet[94]是一种强大的神经网络架构，用于通过空间局部化的特定任务图像条件引导文本到图像的扩散模型[24]。它在主干网络上附加了一个可训练的扩散模型副本，以注入所需条件的空间信息。在这里，我们简要回顾其原理。

首先，空间条件图像\(c_{i}\)被传递到一个小型网络\(E(\cdot)\)，编码到特征空间，如  
\[c_{f}=E\left(c_{i}\right) . (1)\]  
该向量随后被用作重要输入。然后，ControlNet对原始扩散模型进行了若干巧妙的修改。一个具有参数\(\theta\)的预训练神经块\(F(\cdot, \theta)\)，将输入特征图\(x\)转换为输出\(y\)，可以写成  
\[y=F(x ; \theta) . (2)\]  
ControlNet冻结了原始块的参数\(\theta\)，并同时添加了一个带有新参数\(\theta_{c}\)的可训练克隆。添加的块将外部条件向量\(c_{f}\)作为输入，并通过零卷积层与锁定的模型连接，记为\(Z(\cdot ; \cdot)\)。对于单个神经块\(F\)，完整的ControlNet输出为  
\[y_{c}=F(x ; \theta)+Z\left(F\left(x+Z\left(c_{f} ; \theta_{z 1}\right) ; \theta_{c}\right) ; \theta_{z 2}\right), (3)\]  
其中下标中的数字表示参数所属的层和类型。

对于整个Stable Diffusion模型，插入多个ControlNet块以实现对“全局”和“详细”上下文不同尺度的精细控制。可训练的副本应用于扩散U-net的每个编码器级别，输出被添加到跳跃连接和U-net的中间块。ControlNet是一种计算高效的架构，因为在微调时仅需可训练副本进行梯度反向传播，支持高速、低内存消耗的单GPU训练。

ControlNet允许多种控制方法，如各种边缘图、分割图、深度图、遮罩，甚至骨架姿势。它还支持对图像不同方面的串联或同时控制，如形状和颜色。得益于ControlNet带来的极大便利，我们不仅能够从足迹对底部形状进行精细控制，还能从任意草图对屋顶的高度和详细结构进行控制。这也帮助我们实现了与其他使用3D训练数据的3D生成模型相比，仅从2D条件进行低成本训练。

##### 3.2.2 Text2Mesh
Text2Mesh[46]是一种通过自然语言或图像条件对给定粗网格进行风格化的方法。该模块将全局内容视为由给定3D网格规定的大型结构，定义了整体形状和拓扑，将风格视为由其颜色和表面细粒度几何细节决定的特定外观。它通过三个主要组件实现网格风格编辑：神经风格场（NSF）、可微渲染器和相似性比较器。

输入网格\(M\)的顶点\(V \in \mathbb{R}^{n ×3}\)和面\(F \in{1, ..., n}^{m ×3}\)首先被归一化到单位包围盒内，并在整个操作过程中作为参考全局内容固定。神经风格场由三个MLP表示：\(N_{s}\)、\(N_{c}\)和\(N_{d}\)，它们将单位空间中的点\(p\)映射到向量和标量，如  
\[\left(c_{p}, d_{p}\right)=N S F(\gamma(p)) \in\left(\mathbb{R}^{3}, \mathbb{R}\right), (4)\]  
其中\(\gamma(\cdot)\)是位置编码算子。当点位于网格的顶点集合中时，NSF输出的值有效，并作为顶点颜色\(c_{p}\)和沿表面法线的位移\(d_{p} \cdot \overrightarrow{n_{p}}\)传递给网格。在实践中，场中的查询点被设置为\(V\)中的顶点，然后通过给定三角剖分上的可微渲染器进行可视化。Text2Mesh在每次迭代中渲染\(n_{\theta}=5\)个修改后网格的视图，并对渲染图像进行多次2D增强，以增强风格修改的细节。

然后，这些增强后的图像被传递到相似性比较器中计算语义损失。比较器的核心组件是预训练的CLIP模型[62]，它在多模态嵌入空间中起作用。所需风格的文本描述\(t\)首先被传递到文本编码器，如  
\[\phi_{target }=E_{t}(t) \in \mathbb{R}^{512}\]  
然后是图像，如  
\[S^{type }=1 / n_{\theta} \sum_{\theta}(E_{i}(\psi_{type }(I_{\theta}))) \in \mathbb{R}^{512}\]  
其中\(\psi_{type }\)是相应类型的2D增强算子。损失为  
\[L_{sim }=-\sum_{S} sim\left(S, \phi_{target }\right), (5)\]  
其中\(sim(a, b)=(a \cdot b) /(|a| \cdot|b|)\)是\(a\)和\(b\)之间的余弦相似度。损失通过可微渲染器反向传播，然后更新神经风格场中的MLP。当最小化损失时，渲染图像与提示之间的相似度增加，意味着网格的外观逐渐接近纹理描述。

Text2Mesh模块允许我们修改网格表面的详细几何和颜色属性，因此，在我们的建筑模型生成框架中，它用于细化粗网格，使其具有与提示词匹配的精细外观。

#### 3.3 流程概述
我们的框架图示如图3所示。我们的框架中有三个主要功能块：高度图生成、几何重建和外观风格化。我们从给定的足迹和手绘的高度草图开始。高度图生成器中的ControlNet将输出规则平滑的高度图，为几何重建做好准备。下一个块将首先处理生成的图像，去除扩散模型带来的噪声，然后分离高度图中的每个不连续部分，并将它们的形状拟合为多边形。之后，我们根据高度图上的像素值重建屋顶结构的密集点云，并基于点云构建表面。根据输入的建筑参数构建更多的表面，如立面。在几何重建结束时，我们处理粗网格以去除小孔和裂缝，使表面光滑干净。最后，我们使用Text2Mesh模块对密集化的建筑网格进行风格化，并输入文本提示。输出的网格以标准3D数据格式保存，便于下游应用或进一步手动修改。

[//]: # (![图3：我们的流程图示。我们的框架有三个主要功能块：高度图生成、几何重建和外观风格化。]&#40;图3&#41;)

#### 3.4 GeoTexBuild的组件
##### 3.4.1 高度图生成
我们的高度图生成块基于ControlNet的变体，它将矩形调色板转换为规则的彩色图像。高度草图是决定生成高度图的主要控制因素，它可以在几秒钟内轻松手绘。为了适合建筑生成，我们有以下要求：1）图像上的像素值仅表示屋顶上对应点的高度，因此，输入和输出应转换为灰度图，即深度图。2）为了约束生成建筑的底部与足迹完全匹配，足迹应以某种形式作为输入。3）为了对屋顶类型和形状进行细粒度控制，我们应该能够使用不同的调色板网格大小和指示几种



以下是论文剩余部分的完整翻译：


固定模式的屋顶类型提示。

为此，我们将高度草图定义为灰度图像，其值表示屋顶上结构的相对高度，值越大（越亮）表示高度越高。相对意味着它们不是绝对值，可以在后续操作中进行平移或缩放。与大多数使用线条边缘控制生成形状的ControlNet不同，我们决定将足迹作为二进制遮罩\(I_{m}\)输入，以实现更强的控制且减少混淆。

**预处理**：我们首先将草图处理成网格大小为\(n_{g}\)的正方形亮度调色板，  
\[I_{p}^{i, j}=\frac{1}{w_{p}^{2}} \sum_{\substack{(i-1) w_{p}<x \leq i w_{p} \\(j-1) w_{p}<y \leq j w_{p}}} I_{s}(x, y), (6)\]  
其中\(w_{p}=w_{s} / n_{g}\)是调色板网格的宽度，\(w_{s}\)是草图图像的宽度（等于高度），\(I_{p}^{i, j}\)是第\(i\)行第\(j\)列正方形的像素值。然后，亮度调色板通过足迹进行遮罩，以创建清晰的边界，如  
\[I_{m p}=I_{p} \odot I_{m}, \quad (7)\]  
其中\(\odot\)是矩阵的哈达玛积。然后，\(I_{m p}\)作为我们微调的亮度调色板ControlNet的输入，用于高度图生成。

**应用ControlNet**：为了帮助ControlNet从单个亮度调色板理解不同可能的屋顶类型，我们构建了几个固定模式的提示文本\(t\)，描述屋顶是否有多个部分及其大致形状。提示内容列于表2。然后，生成过程可以表示为  
\[I_{h}=C N\left(I_{m p}, t\right) . (8)\]

为了学习遮罩亮度调色板图像与屋顶相对高度图之间的映射，我们使用精心挑选的真实建筑屋顶重建数据集训练了ControlNet模型。数据集和训练细节将在4.1节说明。

##### 3.4.2 几何重建
**图像处理**：一旦获得相对高度图，我们就可以开始重建建筑的几何形状。首先，由于相对高度图是由带有零卷积的ControlNet模型生成的，在控制边缘附近不可避免地会有一些突发噪声。由于扩散模型的性质，纯色区域也会存在其他噪声。我们使用双边滤波器[75]对图像进行滤波，以平滑高度值，同时保留不同部分的边缘，如  
\[I_{b f}(x)=\frac{1}{W(x)} \sum_{x' \in \Omega} I_{h}\left(x'\right) \cdot g_{r}\left(\left\| x-x'\right\| \right) \cdot g_{s}\left(\left\| I_{h}(x)-I_{h}(x') \right\| \right),\]  
其中\(W(x)\)是归一化因子，\(\Omega\)是\(x\)的邻域，\(g_{r}\)和\(g_{s}\)是高斯核。为了确保足够的平滑度，滤波器大小设置为7，\(\sigma_{g r}=9\)，\(\sigma_{g s}=55\)。我们使用形态学算子\(E(\cdot)\)对遮罩进行1像素的腐蚀，以进一步去除边缘附近的亮点，  
\[I_{b f e}=I_{b f} \odot \mathcal{E}\left(I_{m}\right) . (10)\]

**分离和多边形拟合**：在处理后的图像中，我们使用Vtracer（一种最先进的光栅到矢量图形转换器）将每个颜色区域拟合为多边形。在该模块中，像素通过Kopelman算法进行聚类，然后从聚类自底向上构建二叉树，以分层方式将它们放置在画布上。聚类基于亮度差异，我们将其颜色精度设置为6，这意味着一个聚类必须至少有\(256 / 6 ≈42\)的颜色差异才能被视为单独的聚类。精度过低或过高会导致颜色区域缺失或多边形中出现不必要的孔洞。这些聚类将经过路径行走、路径简化、平滑和曲线拟合，矢量化为多边形。我们从Vtracer的输出矢量图中提取每个多边形作为独立的屋顶部分。通过这些矢量化的多边形，我们获得了重建屋顶\({S_{r}}\)外部\({\partial S_{r}}\)的顶点位置。

**图像提升为点云**：我们从每个矢量化多边形包围的高度图像素中重建密集点云。内部像素的位置和高度值直接设置为点的\((x, y)\)和\(z\)坐标。通过去除统计离群点和\(z\)值低于输入高度限制\(h_{min}\)的噪声点来清理点云。

**表面重建**：每个点云部分被发送到法向量估计器和泊松表面重建[31]，八叉树深度设置为6，之后根据屋顶类型进行光顺处理。由于我们在具有相似方向法向量的开放边界点云上进行重建，重建的屋顶表面\({S_{r}}\)不会被封闭。这带来了一个优点和一个缺点。优点是我们可以通过乘以输入建筑参数中的因子来调整建筑绝对高度与屋顶高度之间的比例。缺点是我们发现重建后直接修剪会破坏我们试图保留的平滑边界，导致立面出现条纹。为了解决这个问题，我们利用布尔运算。我们将表面提升到所需的建筑高度，并从上到下挤压它们到地面，以构建每个屋顶部分的网格\({M_{r}}\)。同时，从\({\partial S_{r}}\)自下而上挤压的棱柱\({M_{\partial S_{r}}}\)被构建。然后，重建的最终网格为  
\[\mathcal{M}_{b}=\cup\left(\mathcal{D}\left(\left\{\mathcal{M}_{r}\right\} \cap\left\{\mathcal{M}_{\partial \mathcal{S}_{r}}\right\}\right)\right), (11)\]  
其中\(\cap\)指两个集合中对应网格的交集，形态学算子\(D(\cdot)\)指每个对象在\(x, y\)方向上的1单位膨胀。膨胀补偿了之前应用的腐蚀，并消除了多边形拟合引起的孔洞或裂缝。

##### 3.4.3 外观风格化
从几何重建中，我们获得了表面干净但没有任何精细结构或颜色的网格。我们在这个功能块中丰富其外观，使其接近真实感。首先对网格\(M_{b}\)进行重新网格化，以 densify 表面上的三角形，满足Text2Mesh的分辨率要求。我们将八叉树深度设置为8，以确保顶点能够准确描绘颜色和位移。重新网格化的模型和输入提示被传递到带有微调CLIP的Text2Mesh模块。

我们对Text2Mesh的渲染器进行了微小调整。在原始设置中，\(n_{\theta}\)个视图在正视图周围的正态分布中渲染。然而，尽管在原始论文中对小物体效果良好，但这些视图没有均匀覆盖建筑网格的表面。我们将方位角的分布修改为[0, 2π)内的均匀分布，仰角的分布修改为方差\(3 \sigma=\pi / 4\)的正态分布。


### 4 实验
为了完成整个生成过程，我们在Building3D数据集的特殊渲染图上训练了一个定制的ControlNet模型用于高度图生成，并在精心挑选的高质量图像上微调了一个CLIP模型用于外观风格化。细节在4.1节和4.3节中。几何重建的实验在4.2节中，完整流程的结果和分析在4.4节中。

#### 4.1 定制ControlNet
##### 4.1.1 数据集
在这个模块中，我们试图学习从带有亮度条件的足迹到高度图的映射，因此，我们需要创建相应的成对数据。开源地图和城市数据，如OpenStreetMap，通常不包含足够准确的建筑高度数据来显示房屋屋顶内部的高度变化。我们转向城市规模的建筑重建数据，并从它们的屋顶中提取高度信息。幸运的是，Building3D[78]（图4）提供了超过32k个建筑重建，以点云、线框和网格等多种数据形式存在。我们选择线框，因为它足够准确，不像原始点云那样嘈杂。我们在线框中插入表面，并在Blender中渲染正交顶视图；深度图和遮罩被用作ControlNet训练中的成对数据。我们通过旋转、翻转和随机裁剪将数据集增强了8倍。

[//]: # (![图4：Building3D数据集的数据示例。该数据集提供了超过32k个多种数据形式的建筑重建。我们从填充表面的线框渲染深度图。]&#40;图4&#41;)

##### 4.1.2 训练
训练时，渲染的深度图既用作输入又用作地面真值。作为输入，它们经过3.4.1节中描述的预处理，输出遮罩亮度调色板图像。我们将\(n_{g}\)设置为5到9之间的随机整数，以实现不同精度的条件。作为地面真值，深度图用于计算扩散过程中噪声预测器的损失。

为什么部分输入可以与输出目标相同？这只是在重建图像吗？这仅发生在训练中。回顾一下，我们的目标是从手绘草图生成，但现实中重建的建筑物没有成对的高度草图。多亏了预处理，填补了渲染深度图和手绘草图之间的差距，我们可以以重建的方式训练模型，但以生成的方式进行推理。

为了为不同的屋顶类型准备提示，我们根据线框的顶部结构和几何形状对屋顶进行分类。线框被视为图，并根据它们的连通性分为单片或多片，根据节点的度数分为简单或复杂，根据节点的z坐标范围分为倾斜或平坦。我们为每个类别构建了简单的提示模式，如表2所示。

**表2：不同屋顶类型的提示**  
（表格内容略，原文见）

我们在Stable Diffusion 1.5基础模型上训练了一个定制的ControlNet，使用260k对图像，直至32618个全局步骤。批量大小设置为4，梯度累积步骤设置为4。在最后1000步中解锁SD解码器，学习率从1e-5变为2e-6，遵循ControlNet作者的说明。整个训练过程在单个Nvidia RTX 3090 GPU上用62小时完成。

##### 4.1.3 比较不同的控制组合
我们在这里比较从足迹到高度图的不同控制组合，以证明遮罩和亮度调色板组合带来的优势。

图5中展示了使用相同超参数训练的四个模型，但输入不同的控制：（1）仅线条边缘，（2）线条边缘和亮度调色板，（3）仅遮罩，（4）遮罩和亮度调色板。结果表明，首先，在（1）（3）中，高度是随机生成的，没有亮度调色板；其次，在（1）中，线条边缘导致区分内部和外部的歧义。至于（2），同时绘制线条边缘和高度草图需要额外考虑它们的兼容性，但与（4）相比质量相似。尽管（4）失去了一些非常小和精细的细节，但它在内部部分的边缘产生的噪声更少，这些噪声难以过滤。

此外，我们证明，通过改变屋顶类型的提示，模型可以生成相应的高度图，如图6所示。

[//]: # (![图5：使用相同超参数训练的四个定制ControlNet模型，输入不同的几何控制。推理时使用的相应提示对于（a）（b）是“灰度深度图，多边形形状的简单斜坡联合部分，黑色背景”，对于（c）是“灰度深度图，多边形形状的复杂斜坡组合联合部分，黑色背景”。]&#40;图5&#41;)

[//]: # ()
[//]: # (![图6：通过在输入相同控制时改变不同的提示，我们证明模型可以从单个亮度调色板理解不同可能的屋顶类型。相应的提示对于（a）是“灰度深度图，多边形形状的复杂斜坡和层的多个部分，黑色背景”，对于（b）是“灰度深度图，多边形形状的多个平坦层，黑色背景”，对于（c）是“灰度深度图，多边形形状的复杂斜坡组合联合部分，黑色背景”，对于（d）是“灰度深度图，多边形形状的简单斜坡联合部分，黑色背景”。还显示了重建的表面。（a）中的提示表示更多的层，如烟囱、老虎窗和 soffits 的结构。（c）和（d）的结果由于提示相似而相似。]&#40;图6&#41;)

#### 4.2 几何重建
在这个组件中，主要是图像和几何操作，没有任何可训练的神经块。我们使用Easy3D[51]和Blender构建它们。在这里，我们展示了消融研究的一些比较。

**无图像处理**：重建的表面如图7的第二部分所示。图像处理阶段有助于去除噪声并保持重建屋顶部分的清晰边界。

**无分离和多边形拟合**：重建的表面如图7的第三部分所示。在没有分离和多边形拟合阶段的情况下，各种屋顶部分合并，导致泊松重建中表面过度平滑或出现面包状边界伪影。虽然对单层屋顶的影响相对较小，但在应用于第二列的多层屋顶时，影响是灾难性的。

**无布尔运算**：重建的表面如图7的第四部分所示。用简单的修剪代替布尔运算会破坏我们试图保留的平滑边界，导致立面出现条纹。

[//]: # (![图7：几何重建消融研究的结果。请注意红色框中或箭头指出的不规则形状和不均匀边缘，这是省略关键步骤的直接后果。]&#40;图7&#41;)

#### 4.3 定制Text2Mesh
当我们尝试使用默认的Text2Mesh和ViT-B/32 CLIP模型进行外观风格化时，我们发现该模型常常无法正确区分图像的语义部分。在严重的情况下，它甚至会将背景（如庭院、景观或树木）与前景（建筑物）混淆，从而在目标上绘制背景。由于生成过程的主要指导是相似性比较器，即CLIP模型，我们决定使用手动选择的高质量建筑图像对其进行微调。

##### 4.3.1 数据
为了解决背景混淆问题，我们消除了用于微调的图像的背景，只留下前景建筑物。在Text2Mesh的渲染器中，背景被设置为带有遮罩的白色，因此我们相应地将训练数据中的图像填充为白色。我们从互联网上选择了800多张图像，涵盖了不同视角的各种类型的建筑物。风格的相应文本描述由GPT-4[6]生成，要求是“给我上传图像中的建筑物的提示，描述其形状、设计、材料、颜色和其他特征，不超过30字。”

##### 4.3.2 训练
我们使用OpenCLIP[11]代码库，从’laion2b_s34b_b79k’检查点微调Vit-B/32 CLIP模型。该模型训练了16个 epoch，批量大小为64。这在单个RTX 3090上用20分钟完成。

##### 4.3.3 比较
我们在图8的前两行展示了我们的渲染视点调整后的微调模型与默认Text2Mesh之间的定性比较，在表3中展示了定量比较。默认模型倾向于给整个建筑一个重复的纹理，或将其他背景（如绿色植物）视为建筑的一部分，而微调后的模型可以生成规则的建筑表面和细节。

#### 4.4 结果
定性结果如图9所示。我们在图10中展示了纹理化网格及其顶视图投影与足迹之间的差异。样式提示和渲染视图之间的CLIP相似性分数的定量结果如表3所示。表中的数字是图8中显示的四个固定相机视图的平均分数。CLIP相似性计算为  
\[sim_{C L I P}=<E_{i}(I), E_{t}(t)>, (12)\]  
这是CLIP编码器的编码图像向量和编码文本向量的内积。

**表3：生成模型与提示之间的CLIP相似性分数**  
（表格内容略，原文见）

我们还将生成的网格与基于3D高斯分割的多视图生成方法[76]、基于在3D数据上训练的NeRF的直接3D生成方法[74]和在3D数据上训练的3D-DiT模型[88]进行了比较。由于缺乏对其足迹的控制方法，我们仅展示了从文本提示进行外观建模的比较。此外，从3DGS提取的网格由于3D高斯的椭圆体形状而在表面上存在噪声。尽管直接的3D生成方法似乎产生了详细的几何形状和纹理，但请注意，它们是使用更昂贵的3D数据和多达176个A100 GPU训练超过21,100 GPU小时的。

[//]: # (![图8：不同生成方法之间的比较。请注意，在其他方法中，对足迹没有约束，生成模型的底部形状可能会变化。我们生成的模型的足迹比较在图10中。]&#40;图8&#41;)

#### 4.5 局限性和进一步研究
如4.4节所述，在全面的3D数据集上使用大量GPU资源训练的端到端直接3D生成模型[95,74,25,82,4,41]可能会产生更好的精细几何和纹理分辨率。然而，数据格式和计算能力的限制阻碍了这些前馈模型中有效几何控制的实现，以及它们与我们的管道的集成。因此，我们采用了一种替代方法，将生成过程分解为离散步骤，并提出了一个模块化框架，其中每个阶段在特定条件下生成目标数据。研究如何在渲染或文本之外集成几何控制，同时降低直接3D生成模型的训练成本，以促进特定领域的微调，是未来研究的一个有希望的途径。


### 5 结论
在这项工作中，我们提出了GeoTexBuild，这是一个从足迹、高度草图和风格提示生成纹理化3D建筑模型的模块化框架。我们通过分离生成过程并利用高度图，研究了控制建筑物几何属性的方法。三个组件实现